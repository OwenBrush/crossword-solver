{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim.downloader\n",
    "from custom_transformers import PCAFeatures, SimilarityPrediction, SelectTopNWords\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gensim Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_gensim = gensim.downloader.load('glove-twitter-25')\n",
    "google_gensim = gensim.downloader.load('word2vec-google-news-300')\n",
    "wiki_gensim = gensim.downloader.load('glove-wiki-gigaword-100')\n",
    "gensim_model_dict = {'twitter':twitter_gensim,\n",
    "              'google':google_gensim,\n",
    "              'wiki':wiki_gensim}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert clues into features using word vectorization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(DATA_FOLDER+PCA_TRAIN) and os.path.isfile(DATA_FOLDER+PCA_TEST) :\n",
    "    train = pd.read_csv(DATA_FOLDER+PCA_TRAIN)\n",
    "    test = pd.read_csv(DATA_FOLDER+PCA_TEST)\n",
    "else:    \n",
    "    train = pd.read_csv(DATA_FOLDER+TRAIN)\n",
    "    test = pd.read_csv(DATA_FOLDER+TEST)\n",
    "    train.loc[train['clue'].isna(), 'clue'] = ''\n",
    "    pca_features = PCAFeatures(gensim_model_dict)\n",
    "    pca_features.fit(train)\n",
    "    train = pca_features.transform(train)\n",
    "    test = pca_features.transform(test)\n",
    "    train.to_csv(DATA_FOLDER+PCA_TRAIN, index= False)\n",
    "    test.to_csv(DATA_FOLDER+PCA_TEST, index= False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('answer',axis=1)\n",
    "y_train = train['answer']\n",
    "X_test = test.drop('answer', axis=1)\n",
    "y_test = test['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(DATA_FOLDER+PREDICTED_SIMILARITIES):\n",
    "    X_test = pd.read_csv(DATA_FOLDER+PREDICTED_SIMILARITIES)\n",
    "else:      \n",
    "    random_forest_dict = {'twitter': RandomForestRegressor(),\n",
    "                          'google':RandomForestRegressor(),\n",
    "                          'wiki':RandomForestRegressor()}  \n",
    "    similarity_predictor = SimilarityPrediction(gensim_model_dict=gensim_model_dict,predictor_dict=random_forest_dict)\n",
    "    similarity_predictor.fit(X_train)\n",
    "    X_test = similarity_predictor.transform(X_test)\n",
    "    X_test.to_csv(DATA_FOLDER+PREDICTED_SIMILARITIES,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter:\n",
      "Mean Absolute Error: 0.19433275376997242\n",
      "Median Absolute Error: 0.17121899019999992\n",
      "google:\n",
      "Mean Absolute Error: 0.10628713424573702\n",
      "Median Absolute Error: 0.08929215441999988\n",
      "wiki:\n",
      "Mean Absolute Error: 0.17708801120947698\n",
      "Median Absolute Error: 0.1523335474065\n"
     ]
    }
   ],
   "source": [
    "for model_name in gensim_model_dict.keys():\n",
    "    row_filter = X_test[f'{model_name}_cosine_similarity'].notna()\n",
    "    true = X_test[row_filter][f'{model_name}_cosine_similarity']\n",
    "    predict = X_test[row_filter][f'{model_name}_predicted_similarity']\n",
    "    mean_error = mean_absolute_error(true,predict)\n",
    "    median_error = median_absolute_error(true,predict)\n",
    "    print(f'{model_name}:\\nMean Absolute Error: {mean_error}\\nMedian Absolute Error: {median_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching with twitter vocabulary\n"
     ]
    }
   ],
   "source": [
    "KNOWN_CHARACTER_SETTINGS = ['0.0%_known_characters','20.0%_known_characters','40.0%_known_characters']\n",
    "N_SAMPLES = 10\n",
    "\n",
    "word_selection = SelectTopNWords(5)\n",
    "for known_characters in KNOWN_CHARACTER_SETTINGS:\n",
    "    if os.path.isfile(DATA_FOLDER+known_characters+\"_words.csv\") and os.path.isfile(DATA_FOLDER+known_characters+'_scores.csv') :\n",
    "        words = pd.read_csv(DATA_FOLDER+known_characters+\"_words.csv\", index_col=0)\n",
    "        scores = pd.read_csv(DATA_FOLDER+known_characters+\"_scores.csv\", index_col=0)\n",
    "    else:\n",
    "        words, scores = word_selection.predict( X= X_test[:N_SAMPLES], \n",
    "                                        known_characters= X_test[:N_SAMPLES][known_characters], \n",
    "                                        gensim_models= gensim_model_dict)\n",
    "        words.to_csv(DATA_FOLDER+known_characters+\"_words.csv\")\n",
    "        scores.to_csv(DATA_FOLDER+known_characters+\"_scores.csv\")\n",
    "        \n",
    "    while words.index.max() < X_test.index.max():\n",
    "        start_index = words.index.max()+1\n",
    "        end_index = start_index+N_SAMPLES\n",
    "        new_words, new_scores = word_selection.predict( X= X_test[start_index:end_index], \n",
    "                                known_characters= X_test[start_index:end_index][known_characters], \n",
    "                                gensim_models= gensim_model_dict)\n",
    "        new_words.columns = new_words.columns.astype(str)\n",
    "        new_scores.columns = new_scores.columns.astype(str)\n",
    "        words = pd.concat([words,new_words])\n",
    "        scores = pd.concat([scores,new_scores])\n",
    "        words.to_csv(DATA_FOLDER+known_characters+\"_words.csv\")\n",
    "        scores.to_csv(DATA_FOLDER+known_characters+\"_scores.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0280cb512f1654f6a14f9f049de9766738c3f1045d3ccb87fcae9b6f687f30bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
