{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim.downloader\n",
    "from custom_transformers import PCAFeatures, SimilarityPrediction, SelectTopNWords\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gensim Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_gensim = gensim.downloader.load('glove-twitter-25')\n",
    "google_gensim = gensim.downloader.load('word2vec-google-news-300')\n",
    "wiki_gensim = gensim.downloader.load('glove-wiki-gigaword-100')\n",
    "gensim_model_dict = {'twitter':twitter_gensim,\n",
    "              'google':google_gensim,\n",
    "              'wiki':wiki_gensim}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert clues into features using word vectorization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(DATA_FOLDER+PCA_TRAIN) and os.path.isfile(DATA_FOLDER+PCA_TEST) :\n",
    "    train = pd.read_csv(DATA_FOLDER+PCA_TRAIN)\n",
    "    test = pd.read_csv(DATA_FOLDER+PCA_TEST)\n",
    "else:    \n",
    "    train = pd.read_csv(DATA_FOLDER+TRAIN)\n",
    "    test = pd.read_csv(DATA_FOLDER+TEST)\n",
    "    train.loc[train['clue'].isna(), 'clue'] = ''\n",
    "    pca_features = PCAFeatures(gensim_model_dict)\n",
    "    pca_features.fit(train)\n",
    "    train = pca_features.transform(train)\n",
    "    test = pca_features.transform(test)\n",
    "    train.to_csv(DATA_FOLDER+PCA_TRAIN, index= False)\n",
    "    test.to_csv(DATA_FOLDER+PCA_TEST, index= False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('answer',axis=1)\n",
    "y_train = train['answer']\n",
    "X_test = test.drop('answer', axis=1)\n",
    "y_test = test['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(DATA_FOLDER+PREDICTED_SIMILARITIES):\n",
    "    X_test = pd.read_csv(DATA_FOLDER+PREDICTED_SIMILARITIES)\n",
    "else:      \n",
    "    random_forest_dict = {'twitter': RandomForestRegressor(),\n",
    "                          'google':RandomForestRegressor(),\n",
    "                          'wiki':RandomForestRegressor()}  \n",
    "    similarity_predictor = SimilarityPrediction(gensim_model_dict=gensim_model_dict,predictor_dict=random_forest_dict)\n",
    "    similarity_predictor.fit(X_train)\n",
    "    X_test = similarity_predictor.transform(X_test)\n",
    "    X_test.to_csv(DATA_FOLDER+PREDICTED_SIMILARITIES,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter:\n",
      "Mean Absolute Error: 0.19433275376997242\n",
      "Median Absolute Error: 0.17121899019999992\n",
      "google:\n",
      "Mean Absolute Error: 0.10628713424573702\n",
      "Median Absolute Error: 0.08929215441999988\n",
      "wiki:\n",
      "Mean Absolute Error: 0.17708801120947698\n",
      "Median Absolute Error: 0.1523335474065\n"
     ]
    }
   ],
   "source": [
    "for model_name in gensim_model_dict.keys():\n",
    "    row_filter = X_test[f'{model_name}_cosine_similarity'].notna()\n",
    "    true = X_test[row_filter][f'{model_name}_cosine_similarity']\n",
    "    predict = X_test[row_filter][f'{model_name}_predicted_similarity']\n",
    "    mean_error = mean_absolute_error(true,predict)\n",
    "    median_error = median_absolute_error(true,predict)\n",
    "    print(f'{model_name}:\\nMean Absolute Error: {mean_error}\\nMedian Absolute Error: {median_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_CHARACTER_SETTINGS = ['0.0%_known_characters','20.0%_known_characters','40.0%_known_characters']\n",
    "N_SAMPLES = 5\n",
    "\n",
    "word_selection = SelectTopNWords(5)\n",
    "for known_characters in KNOWN_CHARACTER_SETTINGS:\n",
    "    if os.path.isfile(DATA_FOLDER+known_characters+\"_words.csv\") and os.path.isfile(DATA_FOLDER+known_characters+'_scores.csv') :\n",
    "        words = pd.read_csv(DATA_FOLDER+known_characters+\"_words.csv\", index_col=0)\n",
    "        scores = pd.read_csv(DATA_FOLDER+known_characters+\"_scores.csv\", index_col=0)\n",
    "    else:\n",
    "        words, scores = word_selection.predict( X= X_test[:N_SAMPLES], \n",
    "                                        known_characters= X_test[:N_SAMPLES][known_characters], \n",
    "                                        gensim_models= gensim_model_dict)\n",
    "        words.columns = words.columns.astype(str)\n",
    "        scores.columns = scores.columns.astype(str)\n",
    "        words.to_csv(DATA_FOLDER+known_characters+\"_words.csv\")\n",
    "        scores.to_csv(DATA_FOLDER+known_characters+\"_scores.csv\")\n",
    "        \n",
    "    while words.index.max() < X_test.index.max():\n",
    "        start_index = words.index.max()+1\n",
    "        end_index = start_index+N_SAMPLES\n",
    "        new_words, new_scores = word_selection.predict( X= X_test[start_index:end_index], \n",
    "                                known_characters= X_test[start_index:end_index][known_characters], \n",
    "                                gensim_models= gensim_model_dict)\n",
    "        new_words.columns = new_words.columns.astype(str)\n",
    "        new_scores.columns = new_scores.columns.astype(str)\n",
    "        words = pd.concat([words,new_words])\n",
    "        scores = pd.concat([scores,new_scores])\n",
    "        words.to_csv(DATA_FOLDER+known_characters+\"_words.csv\")\n",
    "        scores.to_csv(DATA_FOLDER+known_characters+\"_scores.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compile_Predictions(predictions):\n",
    "    final_words = {}\n",
    "    final_scores = {}\n",
    "    for i, row in pd.DataFrame(predictions).iterrows():\n",
    "        votes = {}\n",
    "        for chosen_words in row:\n",
    "            if type(chosen_words) is dict:\n",
    "                for word, score in chosen_words.items():\n",
    "                    if word in votes:\n",
    "                        votes[word]+=score\n",
    "                    else:\n",
    "                        votes[word]= score\n",
    "        votes = sorted(votes.items(), key= lambda kv: kv[1], reverse=True)[:5]\n",
    "        final_words[i] = [vote[0] for vote in votes] + [''] * (5 - len(votes))  \n",
    "        final_scores[i] = [vote[1]/len(predictions) for vote in votes] + [np.nan] * (5 - len(votes))    \n",
    "    return final_words, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_words = pd.read_csv(DATA_FOLDER+\"0.0%_known_characters_words.csv\", index_col= 0)\n",
    "predicted_scores = pd.read_csv(DATA_FOLDER+\"0.0%_known_characters_scores.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([y_test,predicted_words],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    99.953333\n",
       "True      0.046667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results['answer'] == results['0']).value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    99.9\n",
       "True      0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((results['answer'] == results['0']) |\n",
    " (results['answer'] == results['1']) | \n",
    " (results['answer'] == results['2']) | \n",
    " (results['answer'] == results['3']) |\n",
    " (results['answer'] == results['4'])).value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0280cb512f1654f6a14f9f049de9766738c3f1045d3ccb87fcae9b6f687f30bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
